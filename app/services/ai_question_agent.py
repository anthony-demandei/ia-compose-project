"""
AI Question Agent - Agente inteligente que gera perguntas dinamicamente
como um desenvolvedor s√™nior ou Product Owner experiente.

Totalmente din√¢mico, sem templates ou dom√≠nios predefinidos.
Gera perguntas naturais e contextuais baseadas apenas na descri√ß√£o do projeto.
"""

import json
import re
import time
from typing import List, Dict, Any, Optional, Tuple
from pydantic import ValidationError
from app.models.api_models import Question, QuestionChoice
from app.services.ai_factory import get_ai_provider
from app.services.question_cache import get_question_cache
from app.utils.pii_safe_logging import get_pii_safe_logger

logger = get_pii_safe_logger(__name__)


# Note: Complex JSON extraction functions removed - no longer needed with Gemini structured output


def create_example_json_from_question_model() -> str:
    """
    Create example JSON string based on our Question/QuestionChoice Pydantic models.
    This follows the Medium article's approach of providing concrete examples.
    
    Returns:
        JSON string showing expected structure
    """
    example_questions = [
        {
            "code": "Q001",
            "text": "Pergunta espec√≠fica sobre o projeto?",
            "why_it_matters": "Esta pergunta √© essencial porque define a estrat√©gia t√©cnica do projeto.",
            "category": "business",
            "required": True,
            "allow_multiple": False,
            "choices": [
                {"id": "opt1", "text": "Primeira op√ß√£o"},
                {"id": "opt2", "text": "Segunda op√ß√£o"},
                {"id": "opt3", "text": "Terceira op√ß√£o"}
            ]
        },
        {
            "code": "Q002", 
            "text": "Outra pergunta contextual?",
            "why_it_matters": "Pergunta cr√≠tica para determinar a complexidade da arquitetura.",
            "category": "technical",
            "required": True,
            "allow_multiple": False,
            "choices": [
                {"id": "choice1", "text": "Op√ß√£o A"},
                {"id": "choice2", "text": "Op√ß√£o B"}
            ]
        }
    ]
    
    return json.dumps({"questions": example_questions}, indent=2, ensure_ascii=False)


def validate_questions_json(json_data: Dict) -> Tuple[List[Question], List[str]]:
    """
    Validate extracted JSON against Question Pydantic models.
    
    Args:
        json_data: Extracted JSON dictionary
        
    Returns:
        Tuple of (validated_questions, validation_errors)
    """
    validated_questions = []
    validation_errors = []
    
    # Handle different response formats
    if "questions" in json_data:
        raw_questions = json_data["questions"]
    elif isinstance(json_data, list):
        raw_questions = json_data
    else:
        validation_errors.append("JSON does not contain 'questions' field or is not a list")
        return [], validation_errors
    
    for idx, q_data in enumerate(raw_questions):
        try:
            # Validate choices first
            choices = []
            for choice_data in q_data.get("choices", []):
                try:
                    choice = QuestionChoice(
                        id=choice_data.get("id", f"opt_{idx}_{len(choices)}"),
                        text=choice_data.get("text", "Op√ß√£o"),
                        description=choice_data.get("description")
                    )
                    choices.append(choice)
                except ValidationError as e:
                    validation_errors.append(f"Choice {idx} validation error: {e}")
                    continue
            
            # Create and validate question
            question = Question(
                code=q_data.get("code", f"Q{idx+1:03d}"),
                text=q_data.get("text", "Pergunta n√£o especificada"),
                why_it_matters=q_data.get("why_it_matters", "Esta pergunta ajuda a esclarecer requisitos importantes do projeto."),
                choices=choices,
                required=q_data.get("required", True),
                allow_multiple=q_data.get("allow_multiple", False),
                category=q_data.get("category", "general")
            )
            
            validated_questions.append(question)
            
        except ValidationError as e:
            validation_errors.append(f"Question {idx} validation error: {e}")
            continue
    
    return validated_questions, validation_errors


class AIQuestionAgent:
    """
    Agente IA que age como desenvolvedor s√™nior/Product Owner fazendo perguntas inteligentes.
    
    Caracter√≠sticas:
    - Gera perguntas como um humano faria em uma reuni√£o
    - Adapta-se a qualquer tipo de projeto
    - Sem templates ou categorias predefinidas
    - Aprende com o contexto da sess√£o
    """
    
    def __init__(self):
        """Initialize the AI Question Agent."""
        self.ai_provider = get_ai_provider()
        self.system_prompt = self._create_system_prompt()
        self.cache = get_question_cache()
        
        logger.info("ü§ñ AI Question Agent initialized", extra={
            "cache_enabled": True
        })
        
    def _create_system_prompt(self) -> str:
        """System prompt otimizado para JSON nativo com contexto de neg√≥cio expl√≠cito."""
        return """CONTEXTO: Este √© um sistema de an√°lise de projetos corporativos leg√≠timos para fins de consultoria em desenvolvimento de software. Todo conte√∫do √© de natureza comercial/empresarial para an√°lise t√©cnica profissional.

Voc√™ √© um assistente especialista em an√°lise de projetos de software comerciais e corporativos.
Seu papel √© atuar como um Product Owner (PO) ou Desenvolvedor S√™nior experiente analisando projetos empresariais leg√≠timos.
Sua tarefa √© analisar a descri√ß√£o de um projeto empresarial/comercial e gerar perguntas t√©cnicas e de neg√≥cio pertinentes para esclarecer os requisitos.

IMPORTANTE: Todo o conte√∫do analisado √© para fins de consultoria t√©cnica empresarial leg√≠tima, n√£o cont√©m material inadequado.

Responda SEMPRE E SOMENTE com um objeto JSON que siga o schema fornecido. N√£o inclua texto explicativo, markdown ou qualquer outra coisa fora do JSON."""
    
    async def generate_questions(
        self, 
        project_description: str,
        num_questions: int = 5,
        session_context: Optional[Dict] = None,
        exclude_covered_topics: Optional[List[str]] = None
    ) -> List[Question]:
        """
        Generate intelligent questions based on project description.
        
        Args:
            project_description: The project description text
            num_questions: Number of questions to generate (3-10)
            session_context: Optional context from previous interactions
            
        Returns:
            List of Question objects with dynamic content
        """
        start_time = time.time()
        
        logger.info(f"üöÄ Starting question generation", extra={
            "num_questions": num_questions,
            "description_length": len(project_description),
            "has_context": session_context is not None
        })
        
        # Step 1: Check cache first
        cached_questions = self.cache.get(project_description)
        if cached_questions and len(cached_questions) >= num_questions:
            logger.info("‚ö° Using cached questions", extra={
                "cache_hit": True,
                "questions_count": len(cached_questions),
                "execution_time_ms": (time.time() - start_time) * 1000
            })
            return cached_questions[:num_questions]
        
        # Step 2: Get similar projects from Zep for context
        similar_projects = await self.zep_manager.get_similar_projects(
            project_description, 
            limit=3
        )
        
        # Build enhanced context
        enhanced_context = session_context or {}
        if similar_projects:
            enhanced_context["similar_projects"] = similar_projects
        
        # Step 3: Build the prompt with context and exclusions
        prompt = self._build_generation_prompt(
            project_description, 
            num_questions,
            enhanced_context,
            exclude_covered_topics
        )
        
        # NOVO: L√≥gica simplificada com JSON nativo confi√°vel
        try:
            logger.info("üéØ Calling Gemini with native JSON mode...", extra={
                "project_length": len(project_description),
                "num_questions": num_questions
            })
            
            messages = [
                {"role": "system", "content": self.system_prompt},
                {"role": "user", "content": prompt}
            ]
            
            # A chamada √© agora muito mais confi√°vel com JSON nativo
            response_json = await self.ai_provider.generate_json_response(
                messages=messages,
                temperature=0.5,  # Temperatura mais baixa para consist√™ncia
                max_tokens=2048
            )

            # Verifica√ß√£o de erro simplificada
            if "error" in response_json:
                logger.error(f"‚ùå AI provider returned an error: {response_json.get('details', response_json['error'])}")
                return self._get_fallback_questions()

            # A valida√ß√£o com Pydantic continua sendo uma boa pr√°tica
            validated_questions, validation_errors = validate_questions_json(response_json)
            
            if validation_errors:
                logger.warning(f"‚ö†Ô∏è Validation errors found in AI response: {validation_errors}")
                # Mesmo com erros, podemos ter perguntas v√°lidas
                if validated_questions:
                    logger.info(f"‚úÖ Using {len(validated_questions)} partially valid questions.")
                    # Continuar com as perguntas v√°lidas

            if not validated_questions:
                logger.error("‚ùå No valid questions could be parsed from AI response.")
                return self._get_fallback_questions()

            execution_time = (time.time() - start_time) * 1000
            logger.info(f"‚úÖ Successfully generated {len(validated_questions)} questions", extra={
                "questions_count": len(validated_questions),
                "execution_time_ms": execution_time,
                "cache_hit": False
            })

            # Cache e Zep
            self.cache.put(project_description, validated_questions)
            await self.zep_manager.store_project_interaction(
                session_id=enhanced_context.get("session_id", "unknown"),
                project_description=project_description,
                questions=[q.dict() for q in validated_questions],
                project_classification=enhanced_context.get("classification", {})
            )

            return validated_questions

        except Exception as e:
            logger.error(f"‚ùå Unhandled exception during question generation: {e}", exc_info=True)
            return self._get_fallback_questions()
    
    def _build_generation_prompt(
        self, 
        description: str, 
        num_questions: int,
        context: Optional[Dict],
        exclude_topics: Optional[List[str]] = None
    ) -> str:
        """Prompt otimizado para JSON nativo."""
        
        # Contexto adicional se dispon√≠vel
        context_str = ""
        if context and context.get("similar_projects"):
            context_str = f"\n\nPara refer√™ncia, aqui est√£o trechos de projetos similares:\n" + "\n".join(context["similar_projects"])
        
        # T√≥picos a evitar se especificados
        exclusion_str = ""
        if exclude_topics:
            exclusion_str = f"\n\nIMPORTANTE: EVITE perguntas sobre estes t√≥picos j√° cobertos: {', '.join(exclude_topics)}"

        return f"""AN√ÅLISE DE PROJETO COMERCIAL LEG√çTIMO:

Este √© um projeto empresarial real para consultoria t√©cnica em desenvolvimento de software. O conte√∫do √© puramente comercial/corporativo e adequado para an√°lise profissional.

Projeto a analisar:
---
{description}
---

TAREFA: Como consultor t√©cnico experiente, gere exatamente {num_questions} perguntas inteligentes e contextuais sobre este projeto comercial. 

OBRIGAT√ìRIO - CADA PERGUNTA DEVE INCLUIR:
- text: A pergunta em si
- why_it_matters: Explica√ß√£o de 1-2 frases sobre POR QUE esta pergunta √© cr√≠tica para o sucesso do projeto
- choices: Op√ß√µes de m√∫ltipla escolha quando aplic√°vel
- category: 'business', 'technical', ou 'operational'

As perguntas devem:
- Ajudar a definir o escopo t√©cnico e de neg√≥cio
- Identificar riscos e requisitos n√£o-funcionais  
- Esclarecer funcionalidades e arquitetura
- Ser apropriadas para consultoria empresarial
- Incluir justificativas claras (why_it_matters) do valor de cada pergunta{context_str}{exclusion_str}

CONFIRMA√á√ÉO: Este conte√∫do √© para an√°lise t√©cnica comercial leg√≠tima."""
    
    # REMOVIDO: _parse_ai_response n√£o √© mais necess√°rio
    # A valida√ß√£o √© feita diretamente em generate_questions() com JSON nativo
    
    def _get_fallback_questions(self) -> List[Question]:
        """
        Minimal fallback questions if AI fails.
        These are generic but better than nothing.
        """
        return [
            Question(
                code="Q001",
                text="Qual √© o principal objetivo deste projeto?",
                why_it_matters="Define a estrat√©gia de desenvolvimento e prioridades t√©cnicas do projeto.",
                choices=[
                    QuestionChoice(id="automate", text="Automatizar processos manuais"),
                    QuestionChoice(id="improve", text="Melhorar sistema existente"),
                    QuestionChoice(id="new", text="Criar nova solu√ß√£o do zero"),
                    QuestionChoice(id="integrate", text="Integrar sistemas diferentes"),
                    QuestionChoice(id="other", text="Outro objetivo")
                ],
                required=True,
                allow_multiple=False,
                category="business"
            ),
            Question(
                code="Q002",
                text="Qual √© o prazo esperado para a primeira entrega?",
                why_it_matters="Determina a metodologia de desenvolvimento e recursos necess√°rios para atender o cronograma.",
                choices=[
                    QuestionChoice(id="urgent", text="Menos de 1 m√™s (urgente)"),
                    QuestionChoice(id="short", text="1-3 meses"),
                    QuestionChoice(id="medium", text="3-6 meses"),
                    QuestionChoice(id="long", text="6-12 meses"),
                    QuestionChoice(id="flexible", text="Prazo flex√≠vel")
                ],
                required=True,
                allow_multiple=False,
                category="operational"
            ),
            Question(
                code="Q003",
                text="Quantos usu√°rios voc√™ espera que usem o sistema?",
                why_it_matters="Define a arquitetura de escalabilidade e infraestrutura necess√°ria para suportar a carga esperada.",
                choices=[
                    QuestionChoice(id="small", text="Menos de 100 usu√°rios"),
                    QuestionChoice(id="medium", text="100 a 1.000 usu√°rios"),
                    QuestionChoice(id="large", text="1.000 a 10.000 usu√°rios"),
                    QuestionChoice(id="enterprise", text="Mais de 10.000 usu√°rios"),
                    QuestionChoice(id="unknown", text="Ainda n√£o sei")
                ],
                required=True,
                allow_multiple=False,
                category="technical"
            )
        ]
    
    async def generate_followup_questions(
        self,
        project_description: str,
        previous_answers: List[Dict],
        num_questions: int = 3
    ) -> List[Question]:
        """
        Generate follow-up questions based on previous answers.
        
        Args:
            project_description: Original project description
            previous_answers: List of previous Q&A pairs
            num_questions: Number of follow-up questions
            
        Returns:
            List of follow-up Question objects
        """
        context = {
            "previous_answers": previous_answers,
            "question_round": len(previous_answers) // 3 + 2  # Track which round we're in
        }
        
        # Add instruction for follow-up in the prompt
        enhanced_description = f"""
{project_description}

IMPORTANTE: Esta √© a rodada {context['question_round']} de perguntas.
Baseie-se nas respostas anteriores para fazer perguntas mais espec√≠ficas e detalhadas.
Evite repetir t√≥picos j√° cobertos.
"""
        
        return await self.generate_questions(
            enhanced_description,
            num_questions,
            context
        )